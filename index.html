<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/dbe.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">
		<script type="text/x-mathjax-config">
    // <![CDATA[
    MathJax.Hub.Config({ 
        TeX: {extensions: ["AMSmath.js", "AMSsymbols.js"]},     
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        showProcessingMessages : false,
        messageStyle : "none" ,    
        showMathMenu: false ,
        tex2jax: {
            processEnvironments: true,
            inlineMath: [ ['$','$'], ["\((","\))"] ],
            displayMath: [ ['$$','$$'], ["\[","\]"] ],
            preview : "none",
            processEscapes: true
        },
        "HTML-CSS": { linebreaks: { automatic:true, width: "latex-container"} }
    });
    // ]]>
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
		<link rel="stylesheet" href="css/latex2html5.css"/> 
     <script type="text/javascript" src="js/latex2html5.min.js"></script>
	 <script src="https://cdnjs.cloudflare.com/ajax/libs/synaptic/1.0.10/synaptic.js"></script>
		<style>
			  
			   @font-face {
				font-family: "Computer Modern";
				src: url('css/cmunrm.otf');
			  }
			  @font-face {
				font-family: "Computer Modern";
				src: url('css/cmunbx.otf');
				font-weight: bold;
			  }
			  @font-face {
				font-family: "Computer Modern";
				src: url('css/cmunti.otf');
				font-style: italic;
			  }


  body {
    font-family: "Computer Modern", sans-serif;
  }
			.reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5,.reveal h6, .reveal p, .reveal div {
				font-family:Computer Modern;
				text-transform: none;
			}
			.reveal button, .reveal input[type=number] {
				border-radius:4px;
				margin-left:5px;
			}
			.reveal input[type=number] {
				margin-bottom:5px;
			}
		</style>


		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<div class="logo_unibas">
					<object data="images/UniBas_Logo_EN_Schwarz_RGB_65-eps-converted-to.svg" type="image/svg+xml">
						<img src="images/UniBas_Logo_EN_Schwarz_RGB_65-eps-converted-to.png" />
					</object>
				</div>
				<div class="logo_dbe">
					<object data="images/DBE_Logo_RGB-eps-converted-to.svg" type="image/svg+xml">
						<img src="images/DBE_Logo_RGB-eps-converted-to.png" />
					</object>
				</div>
				<section class="center">

					<h3>Automated Segmentation of <br>MS Lesions using <br>MD Gated Recurrent Units</h3>
					<br>
					<p>Simon Andermatt, Simon Pezold, Philippe Cattin</p>
					
				</section>
				<section><h4>Learning to Segment</h4>
				Data:
				<div style="height:20%;">
					<img style="border:none;  vertical-align:middle; box-shadow: none" src="images/givendata.png">
			   </div>
				Goal:
			   <div style="height:10%;">
					<img style="border:none; vertical-align:middle; display:inline; width:53%"  src="images/testdata.png">
					<div style="margin-left:10px; padding:20px; border:5px solid gray;  display:inline;">$F_\theta(I)=S$</div>
					<img style="border:none; vertical-align:middle; display:inline; width:13%" class=""  src="images/test04_01_slice080.png">
			   </div>
			   <div style="font-size:50%; padding-top:20px;">(Data from  <a href="https://smart-stats-tools.org/node/26" >Longitudinal Multiple Sclerosis Lesion Segmentation Challenge ISBI 2015</a>)</div>
			   <aside class="notes">	What is Segmentation about? We are given a set of images and corresponding labels, and we want to use these to train the parameters of a function such that we can map new data to their corresponding labels. This function is in our case a neural network. The images you see here are from the longitudinal MS lesion segmentation challenge and we used them for all our experiments.</aside>
				</section>
				
				<section>
					<div>
						<h4>RNN / GRU</h4>
						<img width="50%" style="border:none; vertical-align:middle; box-shadow:none;" src="images/RNN-unrolled.png"/>
						<img width="50%" style="border:none; vertical-align:middle; box-shadow:none;" src="images/LSTM3-var-GRU.png"/><br>
						<div style="font-size:45%; vertical-align:top;">Images:  <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" > http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>.</div>
					</div>
<aside class="notes">	The main building blocks of our network are recurrent neural networks. RNNs are designed to process sequences, as can be seen in the above picture. At each point in the sequence, it takes the input and the previous output of the RNN to create a new output at that point. We are using gated recurrent units, a special type of gated RNN, which is able to find a good approximation faster than an ordinary RNN. It computes for each timestep 3 additional values, the reset gate, the update gate and the proposal activation. The reset gate determines how much of the old state we are allowed to take in to set up our proposal. The update gate is used to determine how much of the old state we want to carry over and how much we want to replace with our porposal activation.</aside>				</section>
				<section>
					<div >
					<h4>MD-GRU</h4>
					<object type="image/svg+xml" data="images/mdgrunotitle2-topath.svg" id="svgObject6"><!--fallback--></object>
					<h4>Network</h4>
					<object type="image/svg+xml" data="images/network-topath.svg" id="svgObject7"><!--fallback--></object>
					</div>
					<aside class="notes">	For images, we have to come up with some sequential way to process them. Multi-dimensional gated recurrent units process the data along each dimension in both directions independently. In the end, the directional responses are summed to gather an output.
For volumetric data, we have 6 directions, which are all handled by an individual convolutional gated recurrent unit. 
Below, you see our network structure. As is common with RNN, we can stack multiple layers, which we do here by also including fully connected layers inbetween.</aside>
				</section>
				<section>
					<h4>Convolutional (C)-GRU</h4>
					<div>
					<object class="" width="100%" type="image/svg+xml" data="images/schemeconvpapersideways-original.svg" id="svgObject"></object>
					</div>
				<aside class="notes">	The mentioned convolutional GRU is detailed here. Its structure is almost the same, with the main difference, that instead of only the data on one line along the data is taken into account, but its local neighborhood too, which is easily handled with convolution operations. As you can see, we still compute an update, a reset and a proposal gate. Up til here, this is the previously introduced MD-GRU setup, which we analyzed in detail.</aside>
				</section>
				<section>
					<h4>Placement of forget gate</h4>
					<div>
					<object class="" width="100%" type="image/svg+xml" data="images/schemeconvpapersideways-a.svg" id="svgObject"></object>
					</div>
					<aside class="notes">	The second great difference between the convolutional GRU and its original form is the location of the reset gate. We tried to mimick the original to see the influence on the results.</aside>
				</section>
				<section>
					<h4>DropConnect on input/state</h4>
					<div>
					<object class="" width="100%" type="image/svg+xml" data="images/schemeconvpapersideways-b.svg" id="svgObject"></object>
					</div>
					<aside class="notes">	We varied regularization through multiplicative gaussian noise, so called DropConnect on either input, state or both weights.</aside>
				</section>
				<section>
					<h4>Batch normalization</h4>
					<div>
					<object class="" width="100%" type="image/svg+xml" data="images/schemeconvpapersideways-c.svg" id="svgObject"></object>
					</div>
					<aside class="notes">	We furthermore evaluated combinations of Batch normalizations applied at different locations in the gating mechanism together and a combination DropConnect. Batch normalization is the process of normalizing and scaling the data prior to feeding it into an activation function, to lessen the covariate shift. In other words, it should help the independent learning of different layers and speed up the training process.</aside>
				</section>
				<section>
					<h4>Weighted sum of states</h4>
					<div>
					<object class="" width="100%" type="image/svg+xml" data="images/mdgruconcatenate-a.svg" id="svgObject"></object>
					</div>
					<aside class="notes">	You can see here again the schematic for the MD-GRU. Instead of simply summing, we evaluated the influence of using a parameterized weighted sum. </aside>
				</section>
				<section>
					<h4>Residual learning</h4>
					<div>
					<object class="" width="100%" type="image/svg+xml" data="images/mdgruconcatenate-b.svg" id="svgObject"></object>
					</div>
					<aside class="notes">	Residual learning is the idea, that it is easier to approximate the change to the input than directly approximating the output. This is simply achieved by adding the input to the output here. </aside>
				</section>
				<section>
					<h4>Data preprocessing and sampling</h4>
					<ul style="line-height:1.5; font-size:85%; margin-top:5%;width:60%;">
						<li>High-pass filtered images:</li>
						<img src="images/showcasehighpass1.png" style="display:inline-block; border:none; box-shadow: none; width:15%; padding-bottom:30px;"><img src="images/showcasehighpass2.png" style="display:inline-block; border:none; box-shadow: none; width:15%; padding-bottom:30px;"><img src="images/anteroposterior.png" style="display:inline-block; border:none; box-shadow: none; width:60%;"/>

						<li class="fragment">Data augmentation: Deformation</li>
						<li class="fragment">Selective Sampling</li>
					</ul>
					<aside class="notes">	We investigated the importance of additional high pass filtering of the data, data augmentation and selective sampling, where we make sure that there are labelled voxels in at least every second sample.</aside>
				</section>
				<section><h4>Results on training data</h4>
					<p style="font-size:55%;">bl: 3000 training iterations on first 4, tested on 5th; DC on state, no def; <br>
					CV bl: average of leave one out CV using bl</p>
					<h5>Validated method steps <span style="color: red;">(vs bl)</span></h5>
						<ol style="line-height:1; font-size:75%; text-align:left;margin:1%">
							<li>High pass filtering of data <span style="color: red;">(-100%)</span></li>
							<li>Summation of directional output <span style="color: red;">(-56%)</span></li>
							<li>Position of reset gate <span style="color: red;">(-39%)</span></li>
						</ol>
					<span class="fragment">
					<h5>Improvements <span style="color: green;">(vs CV bl)</span></h5>
					
					<ol style="line-height:1; font-size:75%; text-align:left; margin:1%">
						<li>Selective sampling <span style="color: green;">(+112%)</span> </li>
						<li>Data augmentation <span style="color: green;">(+83%)</span> </li>
						<li>Residual learning on MD-GRU level <span style="color: green;">(+78%)</span></li>
						<li>DC on state weights, no BN<span style="color: green;">(+66%)</span></li>
						<li>All <span style="color: green;">(+201%)</span></li>
					</ol></span>
					<aside class="notes">	Now we tested various combinations on the training data, by training on 4 and testing on 1 sample, and training 3000 iterations, which give an should be sufficient to give a performance indication.
We validated the high pass filtering step, the simple summation of individual directional outputs as well as the position of the reset gate of the original MD-GRU architecture. All of these seem to be important for good results, especially the high pass filtering, without which there is no useful output.
Compared to baseline, selective sampling, dropconnect only on the state without any batchnormalization, residual learning as well as data augmentation were all important improvements to the existing method. All together, they allowed for a performance improvement of factor 3.</aside>
				</section>
				<section>
					<h4>Results of Longitudinal MS Lesion Segmentation Challenge</h4>
					<div style="font-family:Computer Modern; font-size:60%; width:90%; text-align:left; display:inline-block; margin-top:5%;">
				<b>Table 1. </b> Top 5 entries of the LMSLSC Leaderboard. <i>Columns:</i> Volume Correlation and Dice, Positive Predictive Value, Lesion False Positive Rate and Lesion True Positive Rate in %. <i>Rows:</i> Top 5 entries of challenge leaderboard</div>
					<img src="images/m2017-10-table.png" style=" border:none; box-shadow: none;"/>
					<aside class="notes">	Finally, we used the combination of successful modifications, and were able to reach place one on the LMSLSC of ISBI 2015. For this challenge, we trained the network for 10000 iterations. A old submission which was trained for 40'000 iterations using the original MD-GRU formulation is now ranked 5th. </aside>
				</section>
				<section>
					<div style="font-size:80%; margin-top:250px; margin-bottom:250px;">Acknowledgments:<br>
					 <img style="border:none; max-width:40%; vertical-align:middle; box-shadow: none;" src="images/miaclogo.png"/>
					</div>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				center:false,
				slideNumber: true,
				transition: 'none',
				pdfMaxPagesPerSlide: 1,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					// MathJax
					//{ src: 'plugin/math/math.js', async: false }
				]
			});
		</script>
	</body>
</html>
